{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import csv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed_players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56510 entries, 0 to 56509\n",
      "Data columns (total 34 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   club              56510 non-null  object \n",
      " 1   age               56510 non-null  int64  \n",
      " 2   position          56510 non-null  object \n",
      " 3   mins              56510 non-null  int64  \n",
      " 4   goals             56510 non-null  float64\n",
      " 5   assists           56510 non-null  float64\n",
      " 6   motm              56510 non-null  float64\n",
      " 7   rating            56510 non-null  float64\n",
      " 8   league            56510 non-null  object \n",
      " 9   traded            56510 non-null  int64  \n",
      " 10  w_shots           56510 non-null  float64\n",
      " 11  w_yel             56510 non-null  float64\n",
      " 12  w_red             56510 non-null  float64\n",
      " 13  w_aerials_won     56510 non-null  float64\n",
      " 14  w_tackles         56510 non-null  float64\n",
      " 15  w_interceptions   56510 non-null  float64\n",
      " 16  w_fouls           56510 non-null  float64\n",
      " 17  w_offsides_won    56510 non-null  float64\n",
      " 18  w_clearances      56510 non-null  float64\n",
      " 19  w_dribbled        56510 non-null  float64\n",
      " 20  w_blocks          56510 non-null  float64\n",
      " 21  w_own_goals       56510 non-null  float64\n",
      " 22  w_key_passes      56510 non-null  float64\n",
      " 23  w_dribblings      56510 non-null  float64\n",
      " 24  w_fouled          56510 non-null  float64\n",
      " 25  w_offsides        56510 non-null  float64\n",
      " 26  w_dispossed       56510 non-null  float64\n",
      " 27  w_bad_controls    56510 non-null  float64\n",
      " 28  w_avg_passes      56510 non-null  float64\n",
      " 29  w_crosses         56510 non-null  float64\n",
      " 30  w_long_passes     56510 non-null  float64\n",
      " 31  w_through_passes  56510 non-null  float64\n",
      " 32  w_ps_avg_passes   56510 non-null  float64\n",
      " 33  apps_cat          56510 non-null  int64  \n",
      "dtypes: float64(27), int64(4), object(3)\n",
      "memory usage: 14.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to encode the categorical data, I will use one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To float\n",
    "to_float = df.select_dtypes(include=\"float64\").columns\n",
    "\n",
    "for x in to_float:\n",
    "    df[x] = df[x].astype(\"float16\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.get_dummies(df, columns = ['club','position','league','apps_cat'])\n",
    "# Delete n - 1\n",
    "df = df.drop(['apps_cat_10','league_Premier League','position_MIDFIELDER','club_Wolfsburg'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,df.columns != 'traded'].copy()\n",
    "y = df.loc[:,df.columns == 'traded'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will select a few models to see wich ones perform well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(max_iter=1000), KNeighborsClassifier(), \n",
    "          RandomForestClassifier(random_state=33,max_depth=20),xgb.XGBClassifier(),AdaBoostClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train= MinMaxScaler()\n",
    "scaled_X_train = scaler_train.fit_transform(X_train)\n",
    "\n",
    "scaler_test= MinMaxScaler()\n",
    "scaled_X_test = scaler_test.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : LogisticRegression(max_iter=1000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84      8241\n",
      "           1       0.51      0.11      0.18      3061\n",
      "\n",
      "    accuracy                           0.73     11302\n",
      "   macro avg       0.62      0.54      0.51     11302\n",
      "weighted avg       0.68      0.73      0.66     11302\n",
      "\n",
      "[[7910  331]\n",
      " [2722  339]]\n",
      "---------------------------------------------------------------\n",
      "Model : KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84      8241\n",
      "           1       0.55      0.39      0.45      3061\n",
      "\n",
      "    accuracy                           0.75     11302\n",
      "   macro avg       0.67      0.63      0.65     11302\n",
      "weighted avg       0.73      0.75      0.73     11302\n",
      "\n",
      "[[7287  954]\n",
      " [1881 1180]]\n",
      "---------------------------------------------------------------\n",
      "Model : RandomForestClassifier(random_state=33)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      8241\n",
      "           1       0.97      0.56      0.71      3061\n",
      "\n",
      "    accuracy                           0.88     11302\n",
      "   macro avg       0.92      0.78      0.82     11302\n",
      "weighted avg       0.89      0.88      0.86     11302\n",
      "\n",
      "[[8197   44]\n",
      " [1355 1706]]\n",
      "---------------------------------------------------------------\n",
      "Model : XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      8241\n",
      "           1       0.64      0.26      0.37      3061\n",
      "\n",
      "    accuracy                           0.76     11302\n",
      "   macro avg       0.71      0.60      0.61     11302\n",
      "weighted avg       0.74      0.76      0.72     11302\n",
      "\n",
      "[[7780  461]\n",
      " [2257  804]]\n",
      "---------------------------------------------------------------\n",
      "Model : AdaBoostClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      8241\n",
      "           1       0.51      0.08      0.14      3061\n",
      "\n",
      "    accuracy                           0.73     11302\n",
      "   macro avg       0.63      0.53      0.49     11302\n",
      "weighted avg       0.68      0.73      0.65     11302\n",
      "\n",
      "[[8003  238]\n",
      " [2810  251]]\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model_a in models:\n",
    "        model = model_a\n",
    "        model.fit(scaled_X_train,y_train.values.ravel())\n",
    "        y_pred = model.predict(scaled_X_test)\n",
    "        print('Model :',model_a)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to manage the imbalance using 3 techniques and observe wich one perfoms better. This 3 techniques will be SMOTE, SMOTETomek and StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will scale down the values of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_smote(smote,x,y):\n",
    "    scoring = ['precision', 'recall', 'f1']\n",
    "    for model in models:\n",
    "        if smote:\n",
    "            steps = [('over', SMOTE()), ('model', model)]\n",
    "        else:\n",
    "            steps = [('over', SMOTETomek(sampling_strategy=0.75)), ('model', model)]\n",
    "            \n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        \n",
    "        kfold = RepeatedStratifiedKFold(n_splits=5,n_repeats=3,random_state=33)\n",
    "            \n",
    "        results = cross_validate(pipeline, x, y.values.ravel(), cv=kfold,scoring=scoring)\n",
    "       \n",
    "        precision = results['test_precision']\n",
    "        recall = results['test_recall']\n",
    "        f1 = results['test_f1']\n",
    "        \n",
    "        print('Model :',model)\n",
    "        print(\"Precision mean =\", np.mean(precision), \"std =\",np.std(precision))\n",
    "        print(\"Recall mean =\", np.mean(recall), \"std =\",np.std(recall))\n",
    "        print(\"F1-Score mean =\", np.mean(f1), \"std =\",np.std(f1))\n",
    "        print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(x,y):\n",
    "    scoring = ['precision', 'recall', 'f1']\n",
    "    for model in models:\n",
    "        \n",
    "        kfold = RepeatedStratifiedKFold(n_splits=5,n_repeats=3,random_state=33)\n",
    "            \n",
    "        results = cross_validate(model, x, y.values.ravel(), cv=kfold,scoring=scoring)\n",
    "       \n",
    "        precision = results['test_precision']\n",
    "        recall = results['test_recall']\n",
    "        f1 = results['test_f1']\n",
    "        \n",
    "        print('Model :',model)\n",
    "        print(\"Precision mean =\", np.mean(precision), \"std =\",np.std(precision))\n",
    "        print(\"Recall mean =\", np.mean(recall), \"std =\",np.std(recall))\n",
    "        print(\"F1-Score mean =\", np.mean(f1), \"std =\",np.std(f1))\n",
    "        print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : LogisticRegression(max_iter=1000)\n",
      "Precision mean = 0.3679508100902268 std = 0.002763481146665256\n",
      "Recall mean = 0.6077137505988937 std = 0.008246111599569948\n",
      "F1-Score mean = 0.4583583445645678 std = 0.003935814824372998\n",
      "---------------------------------------------------------------\n",
      "Model : KNeighborsClassifier()\n",
      "Precision mean = 0.40480077523101654 std = 0.003240666700309056\n",
      "Recall mean = 0.7216995513741887 std = 0.00305947285662894\n",
      "F1-Score mean = 0.5186729775023988 std = 0.0033217711766695673\n",
      "---------------------------------------------------------------\n",
      "Model : RandomForestClassifier(random_state=33)\n",
      "Precision mean = 0.8819563777977755 std = 0.004864389375421596\n",
      "Recall mean = 0.7531033581601986 std = 0.005909012964638708\n",
      "F1-Score mean = 0.812440390494457 std = 0.004595866648493326\n",
      "---------------------------------------------------------------\n",
      "Model : XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)\n",
      "Precision mean = 0.5965299126462921 std = 0.006573087252545671\n",
      "Recall mean = 0.3774119081841544 std = 0.008274532791282142\n",
      "F1-Score mean = 0.4622856210760066 std = 0.00745248731308423\n",
      "---------------------------------------------------------------\n",
      "Model : AdaBoostClassifier()\n",
      "Precision mean = 0.3847426941226692 std = 0.005832226556323491\n",
      "Recall mean = 0.4673548499499107 std = 0.013191328171663316\n",
      "F1-Score mean = 0.42195209094043434 std = 0.0069971211961441775\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_models_smote(smote=True,x=scaled_X,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : LogisticRegression(max_iter=1000)\n",
      "Precision mean = 0.4109217359241721 std = 0.00678392736948578\n",
      "Recall mean = 0.43166120795298557 std = 0.010941761325529493\n",
      "F1-Score mean = 0.420990639150891 std = 0.007796358040504468\n",
      "---------------------------------------------------------------\n",
      "Model : KNeighborsClassifier()\n",
      "Precision mean = 0.43779702618547767 std = 0.004476855182752391\n",
      "Recall mean = 0.6726774540721562 std = 0.007132776426834519\n",
      "F1-Score mean = 0.5303753453350407 std = 0.004345688237348155\n",
      "---------------------------------------------------------------\n",
      "Model : RandomForestClassifier(random_state=33)\n",
      "Precision mean = 0.9370012376564391 std = 0.004437663830113479\n",
      "Recall mean = 0.7997080838254144 std = 0.009911009599979186\n",
      "F1-Score mean = 0.8628880953845979 std = 0.005906226997868003\n",
      "---------------------------------------------------------------\n",
      "Model : XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)\n",
      "Precision mean = 0.6204257877416659 std = 0.011863470693197022\n",
      "Recall mean = 0.348425878250449 std = 0.00929255921227145\n",
      "F1-Score mean = 0.44619374870747913 std = 0.009715413975479101\n",
      "---------------------------------------------------------------\n",
      "Model : AdaBoostClassifier()\n",
      "Precision mean = 0.4137752084618113 std = 0.007639942724926211\n",
      "Recall mean = 0.349796890613694 std = 0.015059196716874317\n",
      "F1-Score mean = 0.37892412204624676 std = 0.010066026279529204\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_models_smote(smote=False,x=scaled_X,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : LogisticRegression(max_iter=1000)\n",
      "Precision mean = 0.49050079370906347 std = 0.018642417420074858\n",
      "Recall mean = 0.06559524518262917 std = 0.004110766819022617\n",
      "F1-Score mean = 0.11566875540682088 std = 0.006539502634903284\n",
      "---------------------------------------------------------------\n",
      "Model : KNeighborsClassifier()\n",
      "Precision mean = 0.5581861604399022 std = 0.0065149074002714205\n",
      "Recall mean = 0.39158956931535016 std = 0.011564295721753505\n",
      "F1-Score mean = 0.4601965057301159 std = 0.009152033881228915\n",
      "---------------------------------------------------------------\n",
      "Model : RandomForestClassifier(random_state=33)\n",
      "Precision mean = 0.985017653413404 std = 0.0033144227076752387\n",
      "Recall mean = 0.8170872070498031 std = 0.01113676422819419\n",
      "F1-Score mean = 0.8931858934429454 std = 0.006847838680280675\n",
      "---------------------------------------------------------------\n",
      "Model : XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)\n",
      "Precision mean = 0.7538167683646774 std = 0.01247325542525506\n",
      "Recall mean = 0.2830047969393364 std = 0.010259912695791965\n",
      "F1-Score mean = 0.4114293225625599 std = 0.011765700975761066\n",
      "---------------------------------------------------------------\n",
      "Model : AdaBoostClassifier()\n",
      "Precision mean = 0.5169172913203268 std = 0.02646073917731186\n",
      "Recall mean = 0.0708435055177143 std = 0.008579867128238241\n",
      "F1-Score mean = 0.1244119449501042 std = 0.013555281049304514\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_models(x=scaled_X,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, I would want to develop a Random Forest Classifier. I will use StratifiedKFold since the results are the best but primarly because there is not a modification of the original dataset unlike with SMOTE or SMOTETomek. Similar results, I am always goign with no modification methods.\n",
    "\n",
    "Anyways, I think some overfitti is happening and I guess the reason may be the max depth of the trees taht by default is set to None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search CV to get clue of where to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'max_depth': [30,50,100,200],\n",
    "    'min_samples_leaf': [1, 2, 3,4],\n",
    "    'min_samples_split': [2, 5, 10,20],\n",
    "    'n_estimators': [100, 500, 700,1200],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "kfold = StratifiedKFold(n_splits=3,shuffle=True,random_state=33)\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = rf,n_iter= 25 ,param_distributions = param_grid,scoring='f1', \n",
    "                          cv = kfold, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "best_model_rf = grid_search.fit(scaled_X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'n_estimators': 1200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 50, 'criterion': 'gini', 'bootstrap': False}\n",
      "Best score:  0.7187652609744731\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: \",best_model_rf.best_params_)\n",
    "print(\"Best score: \",best_model_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96      8874\n",
      "           1       0.78      0.98      0.87      2428\n",
      "\n",
      "    accuracy                           0.94     11302\n",
      "   macro avg       0.89      0.95      0.91     11302\n",
      "weighted avg       0.95      0.94      0.94     11302\n",
      "\n",
      "[[8203  671]\n",
      " [  38 2390]]\n"
     ]
    }
   ],
   "source": [
    "rf_ev = RandomForestClassifier(n_estimators=1200, min_samples_split= 2, min_samples_leaf= 1, max_depth= 50, criterion= 'gini', bootstrap= False)\n",
    "rf_ev.fit(scaled_X_train,y_train.values.ravel())\n",
    "y_pred = rf_ev.predict(scaled_X_test)\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     32964\n",
      "           1       1.00      1.00      1.00     12244\n",
      "\n",
      "    accuracy                           1.00     45208\n",
      "   macro avg       1.00      1.00      1.00     45208\n",
      "weighted avg       1.00      1.00      1.00     45208\n",
      "\n",
      "[[32963     1]\n",
      " [    0 12244]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = rf_ev.predict(scaled_X_train)\n",
    "print(classification_report(y_train_pred, y_train))\n",
    "print(confusion_matrix(y_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are really good but there is some overfiting, the model fits perfectly the train set but the precision gap between the 2 predictions is really high. I guess it is because the max depth still being really high. I will try with lower values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.82      0.72      6523\n",
      "           1       0.61      0.39      0.48      4779\n",
      "\n",
      "    accuracy                           0.64     11302\n",
      "   macro avg       0.63      0.60      0.60     11302\n",
      "weighted avg       0.63      0.64      0.62     11302\n",
      "\n",
      "[[5326 1197]\n",
      " [2915 1864]]\n"
     ]
    }
   ],
   "source": [
    "rf_ev = RandomForestClassifier(class_weight='balanced',n_estimators=1200, min_samples_split= 2, min_samples_leaf = 1, max_depth = 8, criterion= 'gini', bootstrap= False)\n",
    "rf_ev.fit(scaled_X_train,y_train.values.ravel())\n",
    "y_pred = rf_ev.predict(scaled_X_test)\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.84      0.74     26027\n",
      "           1       0.65      0.42      0.51     19181\n",
      "\n",
      "    accuracy                           0.66     45208\n",
      "   macro avg       0.66      0.63      0.62     45208\n",
      "weighted avg       0.66      0.66      0.64     45208\n",
      "\n",
      "[[21750  4277]\n",
      " [11213  7968]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = rf_ev.predict(scaled_X_train)\n",
    "print(classification_report(y_train_pred, y_train))\n",
    "print(confusion_matrix(y_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, now not overfitting is happening but I would like to do a last check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBAR SMOTETOMKEK CON TRAIN DATASET Y PREDECIR Y (TEST SIN SMOTETEK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'leaf_size' : [5,9,13,15,21],\n",
    "    'n_neighbors' : [3,7,13,23,29],\n",
    "    'p':[1,2],\n",
    "}\n",
    "kfold = StratifiedKFold(n_splits=3,shuffle=True,random_state=33)\n",
    "knn= KNeighborsClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = knn,n_iter= 25 ,param_distributions = param_grid,scoring='f1', \n",
    "                          cv = kfold, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "best_model_knn = grid_search.fit(scaled_X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'p': 2, 'n_neighbors': 3, 'leaf_size': 5}\n",
      "Best score:  0.39201130704609416\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: \",best_model_knn.best_params_)\n",
    "print(\"Best score: \",best_model_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      8490\n",
      "           1       0.36      0.39      0.38      2812\n",
      "\n",
      "    accuracy                           0.68     11302\n",
      "   macro avg       0.58      0.58      0.58     11302\n",
      "weighted avg       0.69      0.68      0.68     11302\n",
      "\n",
      "[[6535 1955]\n",
      " [1706 1106]]\n"
     ]
    }
   ],
   "source": [
    "knn_ev = KNeighborsClassifier(p= 2,n_neighbors= 3, leaf_size=5)\n",
    "knn_ev.fit(scaled_X_train,y_train.values.ravel())\n",
    "y_pred = knn_ev.predict(scaled_X_test)\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     33200\n",
      "           1       0.88      0.89      0.89     12008\n",
      "\n",
      "    accuracy                           0.94     45208\n",
      "   macro avg       0.92      0.92      0.92     45208\n",
      "weighted avg       0.94      0.94      0.94     45208\n",
      "\n",
      "[[31695  1505]\n",
      " [ 1268 10740]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = knn_ev.predict(scaled_X_train)\n",
    "print(classification_report(y_train_pred, y_train))\n",
    "print(confusion_matrix(y_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is overfitting but we will not try to solve because we can already see that it won´t perform better than the Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go for a Random Forest trained with StratifiedKFold since gives the best perfomance without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ev = RandomForestClassifier(class_weight='balanced',n_estimators=1200, min_samples_split= 2, min_samples_leaf = 1, max_depth = 8, criterion= 'gini', bootstrap= False)\n",
    "rf_ev.fit(scaled_X_train,y_train.values.ravel())\n",
    "y_pred = rf_ev.predict(scaled_X_test)\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
